{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Classification_ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiNQJ8MB4lpb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c8c0f03-231d-462e-b1a0-06db9f3bc538"
      },
      "source": [
        "'''\n",
        "Flower classification using PyTorch\n",
        "dataset: https://www.kaggle.com/alxmamaev/flowers-recognition\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFlower classification using PyTorch\\ndataset: https://www.kaggle.com/alxmamaev/flowers-recognition\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wum7h_REttic",
        "outputId": "d8fca5f7-d87e-41b4-8ef1-deb03db168f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4udW9sWvwSho"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/kaggle\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpCE3Dr9EyE3",
        "outputId": "65b84154-16c3-4fd7-e3dd-23f5f255ce37"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " flowers\t\t\t\t     resnet50_FC_features_512.csv\n",
            " kaggle.json\t\t\t\t    'resnet50_TL_model_94(1)%acc.pth'\n",
            " my.png\t\t\t\t\t     resnet50_TL_model_94%acc.pth\n",
            " resnet50_FC_512_features_with_labels1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZBOt6Mdw8D0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ae5860d1-c8e9-4267-f498-eb477abb00fa"
      },
      "source": [
        "#changing the working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Kaggle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3BHGYToxCOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4768f931-01d1-4436-8bcd-12251fc018d1"
      },
      "source": [
        "!kaggle datasets download -d alxmamaev/flowers-recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /content/gdrive/My Drive/kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZQrh7K4xMRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf7dc81-0d56-48fa-8ba8-124d7adbf63a"
      },
      "source": [
        "#unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTo2cGzmxc0v"
      },
      "source": [
        "DIR_PATH = '/content/gdrive/MyDrive/Kaggle/flowers/flowers'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyUmenUjyc5V"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# pytorch imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T21fxJY7ywXm"
      },
      "source": [
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "transformations = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.CenterCrop((224,224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean,std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.CenterCrop((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean,std)\n",
        "    ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l-8TGRAy0RT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2518c387-b5ee-4069-f8bf-5a9f1faf75c2"
      },
      "source": [
        "# hyperparamters\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 8\n",
        "num_epochs = 50\n",
        "num_classes = 5\n",
        "\n",
        "# device\n",
        "device = None\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ndKLo6y3yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1849b807-4ebc-4364-f7b7-9b9846985c10"
      },
      "source": [
        "total_dataset = torchvision.datasets.ImageFolder(DIR_PATH,transform=transformations['train'])\n",
        "\n",
        "len(total_dataset),total_dataset[0][0].shape,total_dataset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323,\n",
              " torch.Size([3, 224, 224]),\n",
              " {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdt7qTbGy_TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0883bcdb-5145-4c0f-f87c-b7812cb0bf39"
      },
      "source": [
        "# splitting into train and validation sets\n",
        "\n",
        "SPLIT_SIZE = 0.8\n",
        "tot_len = len(total_dataset)\n",
        "\n",
        "train_size = int(SPLIT_SIZE * tot_len)\n",
        "val_size = tot_len - train_size\n",
        "\n",
        "print(f'Training set size = {train_size} \\nValidation set size = {val_size}')\n",
        "\n",
        "train_dataset, val_dataset =  torch.utils.data.random_split(total_dataset,[train_size,val_size])\n",
        "\n",
        "prediction_dataset=total_dataset[0][0]\n",
        "\n",
        "\n",
        "print(prediction_dataset)\n",
        "\n",
        "len(train_dataset),len(val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size = 3458 \n",
            "Validation set size = 865\n",
            "tensor([[[ 0.2111,  0.2796,  0.3652,  ...,  0.5193,  0.5193,  0.4679],\n",
            "         [ 0.1939,  0.2624,  0.3481,  ...,  0.5193,  0.5193,  0.4508],\n",
            "         [ 0.1768,  0.2624,  0.3481,  ...,  0.5022,  0.5022,  0.4166],\n",
            "         ...,\n",
            "         [-1.3473, -1.3644, -1.3644,  ...,  0.1083,  0.1083,  0.0912],\n",
            "         [-1.3644, -1.3644, -1.3644,  ...,  0.1254,  0.1083,  0.1083],\n",
            "         [-1.3644, -1.3644, -1.3644,  ...,  0.1426,  0.1426,  0.1426]],\n",
            "\n",
            "        [[ 0.3452,  0.4153,  0.5028,  ...,  0.6604,  0.6604,  0.6078],\n",
            "         [ 0.3277,  0.3978,  0.4853,  ...,  0.6604,  0.6604,  0.5903],\n",
            "         [ 0.3102,  0.3978,  0.4853,  ...,  0.6429,  0.6429,  0.5553],\n",
            "         ...,\n",
            "         [-1.1954, -1.2129, -1.2129,  ...,  0.1702,  0.1702,  0.1527],\n",
            "         [-1.2129, -1.2129, -1.2129,  ...,  0.1877,  0.1702,  0.1702],\n",
            "         [-1.2129, -1.2129, -1.2129,  ...,  0.2052,  0.2052,  0.2052]],\n",
            "\n",
            "        [[ 0.5311,  0.6356,  0.7228,  ...,  0.8448,  0.8797,  0.8274],\n",
            "         [ 0.5136,  0.6008,  0.7054,  ...,  0.8448,  0.8797,  0.8099],\n",
            "         [ 0.4962,  0.5834,  0.6879,  ...,  0.8448,  0.8622,  0.7751],\n",
            "         ...,\n",
            "         [-1.3339, -1.3513, -1.3513,  ...,  0.3742,  0.3742,  0.3568],\n",
            "         [-1.3513, -1.3513, -1.3513,  ...,  0.3916,  0.3742,  0.3742],\n",
            "         [-1.3513, -1.3513, -1.3513,  ...,  0.4091,  0.4091,  0.4091]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3458, 865)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYsQB3THQz4F",
        "outputId": "6ab57275-3410-49dc-f71f-1cb49befda20"
      },
      "source": [
        "prediction_dataset.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzn7elfVzDGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dd701c-55e7-4cfd-8d51-001b50f184ce"
      },
      "source": [
        "# dataloaders\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         num_workers=4)\n",
        "\n",
        "val_loader = DataLoader(dataset=val_dataset,\n",
        "                       batch_size=1,\n",
        "                       shuffle=True,\n",
        "                       num_workers=4)\n",
        "prediction_loader=DataLoader(dataset=prediction_dataset,batch_size=1,shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMCSKY0nzIak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd43b1c-2abd-4246-c215-26d63ae7732c"
      },
      "source": [
        "# testing dataloading \n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples,labels = examples.next()\n",
        "print(samples.shape,labels.shape) # batch_size=8\n",
        "len(train_loader),len(val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 224, 224]) torch.Size([8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(433, 865)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk-Bdsw3zRdH"
      },
      "source": [
        "# custom CNN model class\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,model,num_classes):\n",
        "        super(ConvNet,self).__init__()\n",
        "        self.base_model = nn.Sequential(*list(model.children())[:-1]) # model excluding last FC layer\n",
        "        self.linear1 = nn.Linear(in_features=2048,out_features=512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=512,out_features=num_classes)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.base_model(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        lin = self.linear1(x)\n",
        "        x = self.relu(lin)\n",
        "        out = self.linear2(x)\n",
        "        return lin, out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RMBgE8rzYgE"
      },
      "source": [
        "model = torchvision.models.resnet50(pretrained=True) # base model\n",
        "\n",
        "model = ConvNet(model,num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DcGQdCuzdKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949180a0-a1ba-4436-c00c-7ab44dd3c092"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (base_model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (linear1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IRN4zwkzhov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "b023c19c-da1a-41b2-9f3a-576910c00ed7"
      },
      "source": [
        "# training loop\n",
        "\n",
        "n_iters = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for ii,(images,labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        _,outputs = model(images)\n",
        "        loss = criterion(outputs,labels)\n",
        "        \n",
        "        # free_gpu_cache()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if (ii+1)%108 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{ii+1}/{n_iters}], Loss = {loss.item():.6f}')\n",
        "            \n",
        "    print('----------------------------------------')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [108/433], Loss = 0.998556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-e3bf14ef7043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# free_gpu_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YEnJm_yzn57"
      },
      "source": [
        "# evaluating model and getting features of every image\n",
        "\n",
        "def eval_model_extract_features(features,true_labels,model,dataloader,phase):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # for entire dataset\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for images,labels in dataloader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            true_labels.append(labels)\n",
        "            \n",
        "            ftrs,outputs = model(images)\n",
        "            features.append(ftrs)\n",
        "\n",
        "            _,preds = torch.max(outputs,1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (preds == labels).sum().item()\n",
        "                \n",
        "        accuracy = n_correct/float(n_samples)\n",
        "\n",
        "        print(f'Accuracy of model on {phase} set = {(100.0 * accuracy):.4f} %')\n",
        "\n",
        "    return features,true_labels\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjJkrdVwGwmq"
      },
      "source": [
        "features = []\n",
        "true_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a1leqfGHBKj"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False,\n",
        "                         num_workers=4)\n",
        "\n",
        "features,true_labels = eval_model_extract_features(features,true_labels,model,dataloader=train_loader,phase='training')\n",
        "\n",
        "print(len(features),len(true_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoIhEXttPr7i"
      },
      "source": [
        "features,true_labels = eval_model_extract_features(features,true_labels,model,dataloader=val_loader,phase='validation')\n",
        "\n",
        "print(len(features),len(true_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__066uQqzzOp"
      },
      "source": [
        "ftrs = features.copy() \n",
        "lbls = true_labels.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvD2OMtxJxmc"
      },
      "source": [
        "for i in range(len(ftrs)):\n",
        "    ftrs[i]=ftrs[i].cpu().numpy()\n",
        "\n",
        "ftrs[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJnf90G8Jxk1"
      },
      "source": [
        "for i in range(len(lbls)):\n",
        "    lbls[i]=lbls[i].cpu().numpy()\n",
        "\n",
        "lbls[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omsThlPrRtG6"
      },
      "source": [
        "type(ftrs),type(lbls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riOhS9vdR41V"
      },
      "source": [
        "ftrs = np.array(ftrs)\n",
        "lbls = np.array(lbls)\n",
        "\n",
        "ftrs.shape,lbls.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2chM26KJSI6P"
      },
      "source": [
        "n_samples = ftrs.shape[0]*ftrs.shape[1]\n",
        "n_features = ftrs.shape[2]\n",
        "ftrs = ftrs.reshape(n_samples,n_features)\n",
        "\n",
        "print(ftrs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOrlzTMlSPSb"
      },
      "source": [
        "n_lbls = lbls.shape[0]\n",
        "lbls = lbls.reshape(n_lbls)\n",
        "\n",
        "print(lbls.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0c6-1iKPsO"
      },
      "source": [
        "# save to csv\n",
        "ftrs_df = pd.DataFrame(ftrs)\n",
        "ftrs_df.to_csv('/content/gdrive/MyDrive/Kaggle/resnet50_FC_features_512.csv',index=False)\n",
        "\n",
        "# reloading the saved csv into a df\n",
        "\n",
        "ftrs_df = pd.read_csv('/content/gdrive/MyDrive/Kaggle/resnet50_FC_features_512.csv')\n",
        "ftrs_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01wsyUKS9b8"
      },
      "source": [
        "# appending labels to the feature set\n",
        "ftrs_df['label'] = lbls\n",
        "\n",
        "ftrs_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj5HSZOgTLcw"
      },
      "source": [
        "ftrs_df.to_csv('/content/gdrive/MyDrive/Kaggle/resnet50_FC_512_features_with_labels1.csv',index=False)\n",
        "\n",
        "print('feature set saved successfully !')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNh3ZlMILLMZ"
      },
      "source": [
        "# save model\n",
        "MODEL_PATH = '/content/gdrive/MyDrive/Kaggle/resnet50_TL_model_94(2)%acc.pth'\n",
        "torch.save(model.state_dict(),MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POQyzMN92oQz"
      },
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "model = ConvNet(model,num_classes)\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3AQ3G6RQDDK"
      },
      "source": [
        "with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        pretrained_dict = ...\n",
        "        \n",
        "         \n",
        "        #model.load_state_dict(torch.load(MODEL_PATH))\n",
        "        \n",
        "        model.eval()\n",
        "\n",
        "        image=total_dataset[0][0]\n",
        "        print(image)\n",
        "        picture=image.clone().numpy()\n",
        "\n",
        "        print(picture)\n",
        "\n",
        "        images = image.to(device).unsqueeze(0)\n",
        "        ftrs,outputs = model(images)\n",
        "        #features.append(ftrs)\n",
        "        _,preds = torch.max(outputs,1)\n",
        "        print(preds)\n",
        "\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "        w, h = 224, 224\n",
        "        # red patch in upper left\n",
        "        picture=np.moveaxis(picture,0,2)\n",
        "      \n",
        "        img = Image.fromarray(picture, 'RGB')\n",
        "\n",
        "        img.save('my.png')\n",
        "        img.show()\n",
        "        print(picture.shape)\n",
        "\n",
        "        '''for images in prediction_dataset:\n",
        "          images = images.to(device)\n",
        "\n",
        "          ftrs,outputs = model(images)\n",
        "          features.append(ftrs)\n",
        "          _,preds = torch.max(outputs,1)\n",
        "          print(preds)\n",
        "            #n_samples += labels.size(0)\n",
        "            #n_correct += (preds == labels).sum().item()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5z3Pq5oc8x"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "w, h = 224, 224\n",
        "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
        " # red patch in upper left\n",
        "\n",
        "img = Image.fromarray(picture, 'RGB')\n",
        "img.save('my.png')\n",
        "img.show()\n",
        "print(picture.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YSQhybGa-GF"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "h = 224\n",
        "w = 224\n",
        "\n",
        "pic = Image.open(\"/content/daisy.jpg\")\n",
        "pix = transformations['train'](pic)\n",
        "print(pix.size())\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  images = pix.to(device).unsqueeze(0)\n",
        "  ftrs,outputs = model(images)\n",
        "  _,preds = torch.max(outputs,1)\n",
        "  print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYIB2uvbcmpo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}